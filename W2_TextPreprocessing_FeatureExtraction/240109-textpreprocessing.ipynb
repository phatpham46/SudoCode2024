{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":9498626,"datasetId":5736987,"databundleVersionId":9710087},{"sourceType":"datasetVersion","sourceId":4013342,"datasetId":2378920,"databundleVersionId":4069179}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **1. Import libraries**","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:52:51.386122Z","iopub.execute_input":"2024-09-21T00:52:51.386600Z","iopub.status.idle":"2024-09-21T00:52:51.826630Z","shell.execute_reply.started":"2024-09-21T00:52:51.386551Z","shell.execute_reply":"2024-09-21T00:52:51.825391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2. Load the data**","metadata":{}},{"cell_type":"code","source":"\nwith open('/kaggle/input/vietnamese-online-news-dataset/news_dataset.json') as f:\n    data = json.load(f)\n\ndf = pd.json_normalize(data)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:52:51.828742Z","iopub.execute_input":"2024-09-21T00:52:51.829239Z","iopub.status.idle":"2024-09-21T00:53:12.548736Z","shell.execute_reply.started":"2024-09-21T00:52:51.829189Z","shell.execute_reply":"2024-09-21T00:53:12.547545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3. Inspect the data**","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:53:12.550050Z","iopub.execute_input":"2024-09-21T00:53:12.550410Z","iopub.status.idle":"2024-09-21T00:53:12.744005Z","shell.execute_reply.started":"2024-09-21T00:53:12.550372Z","shell.execute_reply":"2024-09-21T00:53:12.742745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **4. Text cleaning (Content, Title)**","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n\n!pip install underthesea\n!pip install swifter\n!pip install -U ipywidgets\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:53:13.057101Z","iopub.execute_input":"2024-09-21T00:53:13.057474Z","iopub.status.idle":"2024-09-21T00:53:52.242366Z","shell.execute_reply.started":"2024-09-21T00:53:13.057434Z","shell.execute_reply":"2024-09-21T00:53:52.240883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport unicodedata\n\nstop_words = pd.read_csv('/kaggle/input/stopwords/vietnamese-stopwords-dash.txt', header=None)\n\ndef clean_text(text):\n    # Convert to lowercase\n    text = text.lower() \n    \n    # Normalize Unicode characters\n    text = unicodedata.normalize('NFKC', text)\n    \n    # Remove numbers\n    text = re.sub(r'[^a-zA-ZÀ-ỹ ]+', '', text)\n    \n    # Tokenize the cleaned sentence\n    tokenized_sentence = word_tokenize(text, format='text').split()  # List of words\n    cleaned_sentence = ' '.join(word for word in tokenized_sentence if word not in stop_words[0].tolist())\n\n    return cleaned_sentence  # Return list of tokenized sentences\n    \n\n# Apply the cleaning function\ndf['cleaned_content'] = df['content'].apply(clean_text)\ndf['cleaned_title'] = df['title'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:53:52.244143Z","iopub.execute_input":"2024-09-21T00:53:52.244533Z","iopub.status.idle":"2024-09-21T00:59:53.726168Z","shell.execute_reply.started":"2024-09-21T00:53:52.244493Z","shell.execute_reply":"2024-09-21T00:59:53.725219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **5. Word tokenize**","metadata":{}},{"cell_type":"code","source":"from underthesea import word_tokenize\nimport swifter\ndf['tokenized_content'] = df['cleaned_content'].swifter.apply(lambda x: word_tokenize(x))\ndf['tokenized_title'] = df['cleaned_title'].swifter.apply(lambda x: word_tokenize(x))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:59:53.727773Z","iopub.execute_input":"2024-09-21T00:59:53.728170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **6. Save preprocessed data**\n","metadata":{}},{"cell_type":"code","source":"# save to csv\nfrom pathlib import Path\nPath('/kaggle/working/preprocessed_data/').mkdir(parents=True, exist_ok=True)\n\ndf.to_csv('/kaggle/working/preprocessed_data/processed_data.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}